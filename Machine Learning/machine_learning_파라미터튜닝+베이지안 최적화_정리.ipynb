{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOHXJsyyYwT/EU3TzbgdG2/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wxn_hi5PRunI"},"outputs":[],"source":["Grid search\n","  가능한 모든 조합 > 가장 높은 성능 하이퍼파라미터 조합 > 최적조합 선정\n","  체계적+균등한 전역적인 탐색\n","  탐색 기간이 매우 김\n","  예측 가능 > .predict_proba\n","  주요 파라미터\n","    첫 번째 인수 : n_estimator > 모델 객체\n","    두 번째 인수 : param_grid > 하이퍼파라미터 딕셔너리만들기 > 'key' : 하이퍼파라미터명, 'value' : 탐색구간(딕셔너리, iterable객체)\n","    세 번째 인수 : scoring = '평가 지표'\n","    네 번째 인수 : cv = cv or 정수\n","from sklearn.model_selection import GridSearchCV\n","hp = {\n","\n","}\n","grid_Search = GridSearchCV(model, hp, scoring = '평가 지표', cv = cv, n_jobs = -1)\n","grid_search.fit(train_ft, target)\n","pred = grid_search.predict_proba(test_ft)[1]\n","\n","최적 하이퍼파라미터 조합 cv 점수\n","  grid_search.best_scroe_\n","\n","최적 하이퍼파라미터 조합\n","  grid_search.best_params_\n","\n","※ 탐색한 재조합 다시 모델파라미터에 적용해 학습시키기\n","model = 모델함수 or 클래스(파라미터 설정, **최적조합)\n","model.fit(train_ft, target) > 최적의 파라미터 조합 재학습\n","pred = model.predict_proba(test_ft)[1] > 재학습으로 인한 예측\n","\n","Random search\n","  지정한 횟수만큼 하이퍼파라미터 조합 > 랜덤 샘플링 > 최적조합 선정\n","  주요파라미터\n","    첫 번째 인수 : estimator : 모델 객체\n","    두 번째 인수 : grid와 동일\n","    세 번째 인수 : n_iter = n > 탐색 횟수(default= 10)\n","    네 번째 인수 : scoring = '평가지표'\n","    다섯 번째 인수 : cv = cv객체 or 정수값\n","    여섯 번째 인수 : random_state = 42\n","from sklearn.model_selection import RandomizedSearchCV\n","hp = {\n","\n","}\n","rand_search = RandomizedSearchCV(model, hp, cv = cv, scroing = '평가지표', n_iter = n, n_jobs = -1, random_state = 42)\n","rand_search.fit(train_ft, target)\n","pred = rand_search.predict(test_ft)\n","\n","# 최적 조합 점수\n","rand_search.best_score_\n","# 최적 조합\n","rand_search.best_params_\n","\n","다수 모델 반복문 튜닝\n","  모델 선언\n","from 모델객체\n","\n","[모델클래스, {하이퍼파라미터 탐색범위}]\n","tuning_models = [\n","    [모델객체1, {'파라미터key', '탐색범위value'}],\n","    [모델객체2, {'파라미터key', '탐색범위value'}],\n","    etc\n","]\n","\n","반복문\n","for model_hp in tuning_models:\n","  model_cls, hp = model_hp\n","  rand_search = RandomizedSearchCV(model_cls(), hp, cv = cv, scoring = '평가지표', random_state = 42, n_jobs = -1, n_iter = n)\n","  rand_search.fit(train_ft, target)\n","  model_hp.append(rand_search)\n","\n","모델별 파라미터 조합 확인하기\n","for model_cls, _, search_obj in tuning_models:\n","  print(model_cls.__name__, search_obj.best_score_, search_obj.best_params_)\n","\n","예측하기\n","pred_list = []\n","for _, _, search_obj in tuning_models:\n","  pred = search_obj.predict_proba(test.ft)[1]\n","  pred_list.append(pred)\n","\n","pred = np.array(pred_list).mean(axis = 0)\n","====================================================================================================================================\n","베이지안 최적화\n","  매번 새로운 하이퍼파라미터 조합\n","  최대 or 최소인 최적의 CV값 탐색\n","  optuna\n","optuna모델 튜닝\n","  1.목적함수(콜백) 만들기 > 직접 제작\n","    1-1. optina 라이브러리 > 목적함수에 trial객체 전달\n","    1-2. tiral객체 suggest메서드 > 사전지식 반영 > 하이퍼파라미터 제안+세팅\n","    1-3. 모델학습 및 검증평가 결과 반환\n","  2. 대체모델역할 sampler객체 생성\n","  3. 전체적 튜닝 study객체 생성 > optimize메서드 실행 > 튜닝시작(파라미터 : n_trial = n)\n","  optuna.trial.Trial > trial.suggest_int, trial.suggest_float, trial.suggest_categorical\n","  첫 번째 인수 : 해당 하이퍼파라미터명\n","  두 번째 인수 : 탐색 범위\n","\n","%pip install optuna\n","import optuna\n","# ex)\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import cross_val_score, KFold\n","# 전역 변수 사용 > 비추천\n","def objective(trial):\n","  hp = {\n","      '파라미터명1' : trial.suggest_int('파라미터명1', 탐색범위),\n","      '파라미터명2' : trial.suggest_float('파라미터명2', 탐색범위),\n","      '파라미터명3' : trial.suggest_categorical('파라미터명3', 탐색범위)\n","  }\n","  cv = KFold(k, shuffle = True, random_state = 42)\n","  model = RandomForestClassifier(**hp, random_state = 42)\n","  score = cross_val_score(model, train_ft, target, cv = cv, scoring = '평가지표', n_jobs = -1).mean()\n","  return score\n","\n","# 대체모델역할을 하는 샘플러 객체\n","sampler = optuna.samplers.TPESampler(seed=SEED)\n","\n","# 스터디 객체\n","study = optuna.create_study(\n","    direction=\"maximize\", # '1'에 가까울수록 좋은 경우 : maximize, '0'에 가까울수록 좋은경우 : minimize\n","    sampler = sampler\n",")\n","study.optimize(objective, n_trials=50)\n","study.best_value\n","study.best_trial.params\n","\n","# lambda함수 사용\n","def objective(trial,x,y):\n","  hp = {\n","      동일\n","  }\n","  cv = KFold(k, shuffle = True, random_state = 42)\n","  model = RandomForestClassifier(**hp, random_state = 42)\n","  score = cross_val_score(model, x, y, cv = cv, scoring = '평가지표', n_jobs = -1).mean()\n","  return score\n","\n","# 대체모델역할을 하는 샘플러 객체\n","sampler = optuna.samplers.TPESampler(seed=SEED)\n","\n","# 스터디 객체\n","study = optuna.create_study(\n","    direction=\"maximize\", # '1'에 가까울수록 좋은 경우 : maximize, '0'에 가까울수록 좋은경우 : minimize\n","    sampler = sampler\n",")\n","study.optimize(objective, n_trials=50)\n","study.best_value\n","study.best_trial.params\n","\n","# 클래스 사용\n","class Objective:\n","  def __init__(self, x,y, seed): # seed > 전역변수 선언한 경우\n","    self.x = x\n","    self.y = y\n","    self.seed = seed\n","    self.cv = KFold(k, shuffle = True, random_state = seed)\n","  def __call__(self, trial):\n","    hp = {\n","      동일\n","  }\n","  model = RandomForestClassifier(**hp, random_state = seed)\n","  score = cross_val_score(model, self.x, self.y, self.cv = cv, scoring = '평가지표', n_jobs = -1)\n","\n","# 대체모델역할을 하는 샘플러 객체\n","sampler = optuna.samplers.TPESampler(seed=SEED)\n","\n","# 스터디 객체\n","study = optuna.create_study(\n","    direction=\"maximize\", # '1'에 가까울수록 좋은 경우 : maximize, '0'에 가까울수록 좋은경우 : minimize\n","    sampler = sampler\n",")\n","study.optimize(objective, n_trials=50)\n","study.best_value\n","study.best_trial.params"]}]}