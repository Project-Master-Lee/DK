{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNgodqO4HT4EC3yI/QL/9LJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RrcvFXaNZpd1"},"outputs":[],"source":["from sklearn.모듈명 import 함수 or 클래스명\n","  모듈명 > datasets, metrics, preprocessing, model_selection, ensemble,\n","\n","sklearn 모델 > 지도 학습 > Classifier or Regressor\n","\n","데이터 변환 > encoding, scaling\n","  fit > train_ft(encoding, scaling)\n","  transform > train_ft(encoding, scaling), test_ft(encoding, scaling)\n","  or\n","  fit_transform > train_ft(scaling)\n","\n","모델 학습 > 평가지표\n","  fit > x_train, y_train > 학습데이터\n","  predict > x_valid > 검증 입력데이터\n","  predict_proba(확률)\n","\n","EDA\n","  .info()\n","  .isnull()\n","  .isnull().sum() > Series값\n","  .isnull().sum().sum() > 스칼라값\n","  .shape > 지속적으로 입력하여 확인하기\n","  .select_dtypes('object' or 'int')\n","  .describe() > 수치형 변수 분석\n","\n","target값 뽑기\n","target = train.pop['target컬럼']\n","\n","Feature engineering\n","  객체 = 추출할 변수 선언 > 원하는 feature 담기\n","  train_ft = train[객체].copy()\n","  test_ft = test[객체].copy()\n","  or\n","  train_ft = train.iloc[:,원하는컬럼범위].copy()\n","  test_ft = test.iloc[:,원하는컬럼범위].copy()\n","\n","Data cleaning(결측치 처리)\n","  학습데이터에서 통계량으로 결측치 처리(.skew() .kurt())\n","  .mean()\n","  .median()\n","  .mdoe()[0]\n","\n","Feature Encoding > Encoder 선택\n","  범주형 변수 > 원핫인코딩 > 범주에서 0 or 1로 변환\n","\n","from sklearn.preprocessing import OneHotEncoder > 2차원 데이터만, 1차원 데이터(Series) : df[['컬럼명']]\n","enc = OneHotEncoder(handle_unkwon = 'ignore') > 모르는 값 무시\n","enc.fit(train_ft[문자형feature]) > 학습\n","\n","# enc.transform(train_ft[문자형feature]).toarray() > 변환 후 array 저장\n","# enc.get_feature_names_out() > 원핫인코딩한 피처 컬럼명\n","\n","tmp = pd.DataFrame(\n","    enc.transform(train_ft[문자형feature]).toarray(),\n","    columns = enc.get_feature_names_out()\n",")\n","\n","train_ft = pd.concat([train_ft, tmp], axis = 1).drop(columns = 문자형feature)\n","\n","tmp = pd.DataFrame(\n","    enc.transform(test_ft[문자형feature]).toarray(),\n","    columns = enc.get_feature_names_out()\n",")\n","\n","test_ft = pd.concat([test_ft, tmp], axis = 1).drop(columns = 문자형feature)\n","\n","Feature Scaling > Scaler 모델 선택\n","  데이터 수치 범위 > 0~1 변환\n","\n","MinMaxScaler\n","from sklearn.preprocessing import MinMaxScaler\n","mmScaler = MinMaxScaler()\n","train_ft[train_ft.columns] = mmScaler.fit_transform(train_ft) > 변환해서 만들어낸 feature > train_ft에 추가하기\n","test_ft[test_ft.columns] = mmScaler.transform(test_ft) > 정답데이터 fit x\n","\n","Data split > 데이터 분리\n","from sklearn.model_selection import train_test_split\n","x_train, y_train, x_valid, y_valid = train_test_split(train_ft, target, test_size = ,random_state = 42) > 학습데이터, 타겟 순으로 필수입력\n","x_train.shape, y_train.shape, x_valid.shape, y_valid.shape\n","\n","Train Model\n","  모델 학습\n","  from sklearn.linear_model import LogisticRegression or LogisticClassifier\n","  from sklearn.linear_model import LinearRegression or LinearClassifier\n","  from sklearn.tree import DecisionTreeClassifier\n","  model = 함수 or 클래스(random_state, max_depth)\n","  model.fit(x_train, y_train) > 학습 데이터\n","  pred = model.predict(x_valid) > 검증 입력데이터\n","  or\n","  model.predict_proba(x_valid)[:,1]\n","\n","  평가지표\n","  from sklearn.metrics import mean_squared_error\n","  from sklearn.metrics import root_mean_squared_error or mean_squared_error(y_valid, pred) ** 0.5 > Rmse\n","  from sklearn.metrics import mean_absolute_error\n","  from sklearn.metrics import mean_absolute_percentage_error\n","  from sklearn.metrics import accuracy_score\n","  함수(y_valid, pred)\n","\n","from sklearn.metrics import accuracy_score\n","accuracy_score(y_valid, pred) > 사전 검증평가\n","\n","model.fit(train_ft, target) > 전체 데이터 모델에 재학습\n","pred = model.transform(test_ft)\n","\n","pd.DataFrame(pred, columns = ['target']).to_csv('파일명.csv', index = False)\n","\n","순서\n","EDA > 결측치 처리 > Feature engineering > Feature Scaling > Data_split > Model train > 전체 데이터 재학습 + pred > 파일 생성\n","===================================================================================================================================================\n","\n","평가 지표\n","MSE\n","  이상치 민감\n","  손실함수 최소화\n","  극단값에 패널티 포함시키는 경우\n","from sklearn.metrics import mean_squared_error\n","mean_squared_error(y_valid, pred)\n","\n","RMSE\n","  MSE와 동일\n","from sklearn.metrics import root_mean_squared_error\n","root_mean_squared_error(y_valid, pred)\n","\n","MAE\n","  이상치 영향 x\n","from sklearn.metrics import mean_absolute_error\n","mean_absolute_error(y_valid, pred)\n","\n","MAPE\n","  MAE 확률값\n","  이상치 영향 x\n","from sklearn.metrics import mean_absolute_percentage_error\n","mean_absolute_percentage_error(y_valid, pred)\n","\n","linear_model > LinearRegression or LinearClassifier\n","  from sklearn.linear_model import LinearRegression or LinearClassifier > 저성능\n","\n","Dummy\n","  데이터 내 최빈값 반환\n","from sklearn.dummy import DummyClassifier\n","dummy = DummyClassifier(strategy = 'most_frequent')\n","dummy.fit(x_train, y_train)\n","pred_dummy = dummy.predict(x_valid)\n","\n","Logistic\n","from sklearn.linear_model import LogisticRegression\n","lr = LogisticRegression(random_state = 42)\n","lr.fit(x_train, y_train)\n","pred_lr = lr.predict(x_valid)\n","pred_proba = lr.predict_proba(x_valid)[:,1] > 이진 분류일 경우\n","\n","accuracy_score > 비선호\n","from sklearn.metrics import accuracy_score\n","accuracy_score(y_valid, pred)\n","\n","precision_score & recall_score\n","  상충 관계\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","precision_score(y_valid, pred)\n","recall_score(y_valid, pred)\n","\n","임계값 = thresholds\n","  확률 > 0.5 이상\n","  실수 > '0'+양수 > '1',  음수 > '0'\n","thresholds = 실수값\n","pred = np.where(pred_proba >= thresholds, 1, 0)\n","precision_score(y_valid, pred)\n","recall_score(y_valid, pred)\n","\n","F1-score\n","from sklearn.metrics import f1_score\n","f1_score(y_valid, pred)\n","\n","Roc Auc\n","  '1'에 가까울수록 좋음\n","from sklearn.metrics import roc_auc_score\n","roc_auc_score(y_valid, pred)\n","=========================================================================\n","Multi-Classification > 다중 분류\n","  micro > 다수 분포 or 불균형\n","  macro > 정확한 비즈니스 문제\n","  weight > 가중 평균\n","f1_score(y_valid, pred, average = 'micro')\n","f1_score(y_valid, pred, average = 'macro')\n","f1_score(y_valid, pred, average = 'weighted')\n","\n","분류에 따른 확률 출력\n","  이진 분류 > 시그모이드\n","  다중 분류 > 소프트맥스\n","\n","logloss\n","  '0'에 가까울수록 좋음\n","  다중분류 평가지표\n","from sklearn.metrics import log_loss\n","log_loss(y_valid, pred)\n","==========================================================================\n","Data Leakage\n","  예측 시 사용불가 데이터\n","  결과로 과대평가 + 모델의 일반화 가능성 저하\n","\n","  발생 예시\n","  test데이터 fit + groupby 실행\n","  test dataset 내 서로 다른 샘플로 집계해 피처 생성\n","  test data로 집계한 통계치로 결측치처리\n","\n","  해결방안\n","  test dataset 대신 train dataset으로 집계한 데이터로 merge\n","  test dataset을 nunique로 묶는 경우\n","  train data에서 집계한 통계치로 결측치 처리\n","\n","Data Leakage 코드 예시\n","test.groupby('그룹핑대상컬럼')['집계대상컬럼명'].집계함수()\n","\n","df = pd.concat([train, test], axis = 1)\n","df.집계함수() > 집계함수로 결측치 처리\n","\n","enc.fit_transform(test)\n","scaler.fit_transform(test)"]}]}