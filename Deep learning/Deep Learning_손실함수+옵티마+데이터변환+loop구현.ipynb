{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNQJXLmxLOF4/NnKWdGfJlM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 데이터 불러오기"],"metadata":{"id":"5eKAV0lzHv68"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","DATA_PATH = \"/content/drive/MyDrive/data/\"\n","\n","SEED = 42 # 시드값\n","\n","# 데이터 블러오기\n","train = pd.read_csv(f\"{DATA_PATH}titanic_train.csv\") # 학습데이터\n","test = pd.read_csv(f\"{DATA_PATH}titanic_test.csv\") # 테스트 데이터\n","\n","# 결측치 처리\n","age_mean = train[\"age\"].mean()\n","fare_median = train[\"fare\"].median()\n","cabin_unk = \"UNK\"\n","embarked_mode = train[\"embarked\"].mode()[0]\n","train[\"age\"] = train[\"age\"].fillna(age_mean)\n","train[\"cabin\"] = train[\"cabin\"].fillna(cabin_unk)\n","test[\"age\"] = test[\"age\"].fillna(age_mean)\n","test[\"fare\"] = test[\"fare\"].fillna(fare_median)\n","test[\"cabin\"] = test[\"cabin\"].fillna(cabin_unk)\n","test[\"embarked\"] = test[\"embarked\"].fillna(embarked_mode)\n","\n","# 특성으로 사용할 변수 선택\n","cols = [\"age\",\"sibsp\",\"parch\",\"fare\",\"pclass\",\"gender\",\"embarked\"]\n","train_ft = train[cols].copy()\n","test_ft = test[cols].copy()\n","\n","# 범주형 변수 원핫인코딩\n","cols = ['gender','embarked']\n","enc = OneHotEncoder(handle_unknown = 'ignore')\n","enc.fit(train[cols])\n","tmp = pd.DataFrame(\n","    enc.transform(train_ft[cols]).toarray(),\n","    columns = enc.get_feature_names_out()\n",")\n","train_ft = pd.concat([train_ft,tmp],axis=1).drop(columns=cols)\n","tmp = pd.DataFrame(\n","    enc.transform(test_ft[cols]).toarray(),\n","    columns = enc.get_feature_names_out()\n",")\n","test_ft = pd.concat([test_ft,tmp],axis=1).drop(columns=cols)\n","\n","# Min-Max Scaling\n","scaler = MinMaxScaler()\n","scaler.fit(train_ft)\n","train_ft = scaler.transform(train_ft)\n","test_ft = scaler.transform(test_ft)\n","\n","# 정답 데이터\n","target = train[\"survived\"].to_numpy().reshape(-1,1)\n","\n","train_ft.shape, test_ft.shape, target.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJo4QnSfHyKR","executionInfo":{"status":"ok","timestamp":1732367446439,"user_tz":-540,"elapsed":2885,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"3be737da-20eb-44e8-de66-8f3e4b053e26"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["((916, 10), (393, 10), (916, 1))"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["target"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"LjMj7XulJZkk","executionInfo":{"status":"ok","timestamp":1732367467194,"user_tz":-540,"elapsed":443,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"8f6e0f5b-e250-4622-83b0-7de43692b2b6"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0]])"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["# WorkFlow\n","1. 데이터 전처리\n","2. 학습 데이터를 텐서로 변경\n","3. 인공 신경망 모델 객체 생성\n","4. 하이퍼파라미터 정리(손실함수 및 옵티마이저 등 선택)\n","5. 학습 및 테스트 예측하는 loop 구현"],"metadata":{"id":"4batPpr_His5"}},{"cell_type":"markdown","source":["# 손실함수"],"metadata":{"id":"1w7TduerG0W-"}},{"cell_type":"markdown","source":["## 회귀문제\n","  - 정답 데이터 2차원형식으로 생성"],"metadata":{"id":"WERhtYEwG4QN"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"s_dQJLdVGMe5","executionInfo":{"status":"ok","timestamp":1732367557944,"user_tz":-540,"elapsed":5074,"user":{"displayName":"이동규","userId":"01303882340467999707"}}},"outputs":[],"source":["import torch"]},{"cell_type":"code","source":["torch.manual_seed(SEED)\n","# 2개의 샘플 + 3개 피처\n","x = torch.randn(2,3)\n","\n","# 2개의 정답 데이터(1차원 형태 시 에러 발생, 2차원형태으로 생성)\n","y = torch.rand(2,1)\n","\n","x.shape, y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bEyLiWzPGz8o","executionInfo":{"status":"ok","timestamp":1732367577883,"user_tz":-540,"elapsed":588,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"74018ed1-27b4-47d6-8755-34e21e11cae1"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([2, 3]), torch.Size([2, 1]))"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L4_TT4SYGz6R","executionInfo":{"status":"ok","timestamp":1732367578450,"user_tz":-540,"elapsed":570,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"aa9ca657-b854-4055-d128-d36a3504f182"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.3367,  0.1288,  0.2345],\n","        [ 0.2303, -1.1229, -0.1863]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50QhIrLIGz4A","executionInfo":{"status":"ok","timestamp":1732367578450,"user_tz":-540,"elapsed":2,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"3309de18-4849-4603-ba66-1e6cf3c2c4f7"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.8694],\n","        [0.5677]])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["x.shape[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y06lNKDNGz1m","executionInfo":{"status":"ok","timestamp":1732367779187,"user_tz":-540,"elapsed":1143,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"bfaf91bb-4660-4d8a-caff-d6293154ab37"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["model = torch.nn.Linear(x.shape[1], 1) # 입력데이터 피처 개수: 3, 출력데이터 예측값 개수: 1\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLQzIUwjGzzP","executionInfo":{"status":"ok","timestamp":1732367802594,"user_tz":-540,"elapsed":1021,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"bae59992-ad93-4e60-c829-35ccb927b480"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=3, out_features=1, bias=True)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["pred = model(x)\n","pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OXTKvMf0Gzwy","executionInfo":{"status":"ok","timestamp":1732367844950,"user_tz":-540,"elapsed":473,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"32a23d90-bbe0-437d-fe84-56957302157b"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.2729],\n","        [0.1581]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["### MSE"],"metadata":{"id":"b-NNNf8tMZTl"}},{"cell_type":"code","source":["# 손실을 계산할 수 있는 손실함수 객체 반환\n","loss_fn = torch.nn.MSELoss()\n","\n","# 손실함수 내 첫 번째 인수: 예측값, 두 번째 인수: 정답값 전달\n","loss = loss_fn(pred, y)\n","loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KfozkjeKGzuX","executionInfo":{"status":"ok","timestamp":1732367888295,"user_tz":-540,"elapsed":419,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"e7b0e4a3-539b-49b2-dfe4-53c43455ffcf"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.2618, grad_fn=<MseLossBackward0>)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# 역전파\n","loss.backward"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":186},"id":"cui1gq71Gzr6","executionInfo":{"status":"ok","timestamp":1732367900872,"user_tz":-540,"elapsed":4,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"59944112-d52c-46c3-a12f-030989de8d09"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method Tensor.backward of tensor(0.2618, grad_fn=<MseLossBackward0>)>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>torch._tensor.Tensor.backward</b><br/>def backward(gradient=None, retain_graph=None, create_graph=False, inputs=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/_tensor.py</a>Computes the gradient of current tensor wrt graph leaves.\n","\n","The graph is differentiated using the chain rule. If the tensor is\n","non-scalar (i.e. its data has more than one element) and requires\n","gradient, the function additionally requires specifying a ``gradient``.\n","It should be a tensor of matching type and shape, that represents\n","the gradient of the differentiated function w.r.t. ``self``.\n","\n","This function accumulates gradients in the leaves - you might need to zero\n","``.grad`` attributes or set them to ``None`` before calling it.\n","See :ref:`Default gradient layouts&lt;default-grad-layouts&gt;`\n","for details on the memory layout of accumulated gradients.\n","\n",".. note::\n","\n","    If you run any forward ops, create ``gradient``, and/or call ``backward``\n","    in a user-specified CUDA stream context, see\n","    :ref:`Stream semantics of backward passes&lt;bwd-cuda-stream-semantics&gt;`.\n","\n",".. note::\n","\n","    When ``inputs`` are provided and a given input is not a leaf,\n","    the current implementation will call its grad_fn (though it is not strictly needed to get this gradients).\n","    It is an implementation detail on which the user should not rely.\n","    See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.\n","\n","Args:\n","    gradient (Tensor, optional): The gradient of the function\n","        being differentiated w.r.t. ``self``.\n","        This argument can be omitted if ``self`` is a scalar.\n","    retain_graph (bool, optional): If ``False``, the graph used to compute\n","        the grads will be freed. Note that in nearly all cases setting\n","        this option to True is not needed and often can be worked around\n","        in a much more efficient way. Defaults to the value of\n","        ``create_graph``.\n","    create_graph (bool, optional): If ``True``, graph of the derivative will\n","        be constructed, allowing to compute higher order derivative\n","        products. Defaults to ``False``.\n","    inputs (sequence of Tensor, optional): Inputs w.r.t. which the gradient will be\n","        accumulated into ``.grad``. All other tensors will be ignored. If not\n","        provided, the gradient is accumulated into all the leaf Tensors that were\n","        used to compute the :attr:`tensors`.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 525);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["### MAE"],"metadata":{"id":"SpOJlfjeLIkF"}},{"cell_type":"code","source":["torch.manual_seed(SEED)\n","# 2개의 샘플 + 3개 피처\n","x = torch.randn(2,3)\n","\n","# 2개의 정답 데이터(1차원 형태 시 에러 발생, 2차원형태으로 생성)\n","y = torch.rand(2,1)"],"metadata":{"id":"wnKc72jRGzpo","executionInfo":{"status":"ok","timestamp":1732368774111,"user_tz":-540,"elapsed":581,"user":{"displayName":"이동규","userId":"01303882340467999707"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["y.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MDziBEkqOY-f","executionInfo":{"status":"ok","timestamp":1732368774112,"user_tz":-540,"elapsed":10,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"8dd39e27-1959-4fb6-eee8-280cde61dd7a"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.float32"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["model = torch.nn.Linear(x.shape[1], 1) # 입력데이터 피처 개수: 3, 출력데이터 예측값 개수: 1\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hgJvxsyOGznM","executionInfo":{"status":"ok","timestamp":1732368304104,"user_tz":-540,"elapsed":2,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"7d987cb2-5ac1-476a-e5e2-46f3a241b247"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=3, out_features=1, bias=True)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["pred = model(x)\n","pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZWbxqTfuMmX-","executionInfo":{"status":"ok","timestamp":1732368304632,"user_tz":-540,"elapsed":2,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"c98b48c8-1e99-42d9-9ebb-5a00c9d4cab6"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.2729],\n","        [0.1581]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["loss_fn = torch.nn.L1Loss()\n","loss = loss_fn(pred, y)\n","loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1RZfJ8LnGzk4","executionInfo":{"status":"ok","timestamp":1732368305539,"user_tz":-540,"elapsed":4,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"a6cbb2dc-3b07-4c74-ed9e-e546c8cc34c1"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.5031, grad_fn=<MeanBackward0>)"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# 역전파\n","loss.backward"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":186},"id":"lQjynIdbGzie","executionInfo":{"status":"ok","timestamp":1732368313970,"user_tz":-540,"elapsed":434,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"c26530c0-e606-4ff5-9398-2fc5e26afac7"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method Tensor.backward of tensor(0.5031, grad_fn=<MeanBackward0>)>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>torch._tensor.Tensor.backward</b><br/>def backward(gradient=None, retain_graph=None, create_graph=False, inputs=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/_tensor.py</a>Computes the gradient of current tensor wrt graph leaves.\n","\n","The graph is differentiated using the chain rule. If the tensor is\n","non-scalar (i.e. its data has more than one element) and requires\n","gradient, the function additionally requires specifying a ``gradient``.\n","It should be a tensor of matching type and shape, that represents\n","the gradient of the differentiated function w.r.t. ``self``.\n","\n","This function accumulates gradients in the leaves - you might need to zero\n","``.grad`` attributes or set them to ``None`` before calling it.\n","See :ref:`Default gradient layouts&lt;default-grad-layouts&gt;`\n","for details on the memory layout of accumulated gradients.\n","\n",".. note::\n","\n","    If you run any forward ops, create ``gradient``, and/or call ``backward``\n","    in a user-specified CUDA stream context, see\n","    :ref:`Stream semantics of backward passes&lt;bwd-cuda-stream-semantics&gt;`.\n","\n",".. note::\n","\n","    When ``inputs`` are provided and a given input is not a leaf,\n","    the current implementation will call its grad_fn (though it is not strictly needed to get this gradients).\n","    It is an implementation detail on which the user should not rely.\n","    See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.\n","\n","Args:\n","    gradient (Tensor, optional): The gradient of the function\n","        being differentiated w.r.t. ``self``.\n","        This argument can be omitted if ``self`` is a scalar.\n","    retain_graph (bool, optional): If ``False``, the graph used to compute\n","        the grads will be freed. Note that in nearly all cases setting\n","        this option to True is not needed and often can be worked around\n","        in a much more efficient way. Defaults to the value of\n","        ``create_graph``.\n","    create_graph (bool, optional): If ``True``, graph of the derivative will\n","        be constructed, allowing to compute higher order derivative\n","        products. Defaults to ``False``.\n","    inputs (sequence of Tensor, optional): Inputs w.r.t. which the gradient will be\n","        accumulated into ``.grad``. All other tensors will be ignored. If not\n","        provided, the gradient is accumulated into all the leaf Tensors that were\n","        used to compute the :attr:`tensors`.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 525);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["## 분류문제"],"metadata":{"id":"YlkXh4VOMuHy"}},{"cell_type":"markdown","source":["### BCE(Binary Cross Entropy)\n","- 이진 분류 문제에서 사용되는 손실함수"],"metadata":{"id":"TE4w141PM6ui"}},{"cell_type":"code","source":["x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"37ORG5UIM6To","executionInfo":{"status":"ok","timestamp":1732368979686,"user_tz":-540,"elapsed":478,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"5d1792a9-eb55-463e-dee1-803fd29ecc78"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.3367,  0.1288,  0.2345],\n","        [ 0.2303, -1.1229, -0.1863]])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["torch.Tensor([0,1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBIiUyR_PXmo","executionInfo":{"status":"ok","timestamp":1732369046976,"user_tz":-540,"elapsed":419,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"fa6574d1-1585-4047-ae6e-40440fea2dcf"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 1.])"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["# Tensor > float32\n","y = torch.Tensor([0,1]).view(-1,1)\n","y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_gUhjz5GzgU","executionInfo":{"status":"ok","timestamp":1732368980229,"user_tz":-540,"elapsed":2,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"f0e8e2d9-167b-4f66-ed53-362e5e9195a9"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.],\n","        [1.]])"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["y.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"brpXcCOKO5Ct","executionInfo":{"status":"ok","timestamp":1732368980661,"user_tz":-540,"elapsed":3,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"fa57a0bb-72c1-4e46-a62e-0a998c379ca7"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.float32"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["x.shape[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjEdfLTWPrt8","executionInfo":{"status":"ok","timestamp":1732369111060,"user_tz":-540,"elapsed":429,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"eb0b0ab4-792b-4b80-fe82-5504740c480d"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["model = torch.nn.Linear(x.shape[1], 1) # 입력 데이터 피처 개수: 3, 출력데이터 예측값 개수: 1"],"metadata":{"id":"80hNNWiPPmXd","executionInfo":{"status":"ok","timestamp":1732369262141,"user_tz":-540,"elapsed":649,"user":{"displayName":"이동규","userId":"01303882340467999707"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["pred = model(x)\n","pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LHqk9h3hP8rH","executionInfo":{"status":"ok","timestamp":1732369262141,"user_tz":-540,"elapsed":3,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"38195358-d1ad-4b6e-eb8e-10fc3df12576"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.2448],\n","        [0.2041]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["- 정의한 모델의 출력이 시그모이드 함수를 통과한 경우"],"metadata":{"id":"mdplc3zgQAZR"}},{"cell_type":"code","source":["# 시그모이드 함수르 반환하는 클래스\n","sig = torch.nn.Sigmoid()\n","loss_fn = torch.nn.BCELoss()\n","loss_fn(sig(pred), y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1_ZCPA0cP8pj","executionInfo":{"status":"ok","timestamp":1732369295729,"user_tz":-540,"elapsed":450,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"b7663f9e-63a6-4c20-c8a0-9202fd10b50a"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.7097, grad_fn=<BinaryCrossEntropyBackward0>)"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["- 정의한 모델의 출력이 시그모이드 함수를 통과하지 않은 경우\n","- 파이토치 권장 > 속도 빠름\n","- 시그모이드함수 이미 포함되어 있어서 언급 x"],"metadata":{"id":"mf3gCDdEQFjH"}},{"cell_type":"code","source":["loss_fn = torch.nn.BCEWithLogitsLoss()\n","loss_fn(pred, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IeJrUhEWP8nZ","executionInfo":{"status":"ok","timestamp":1732369338414,"user_tz":-540,"elapsed":831,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"e1361939-7806-4b90-91c7-30b69968c7a8"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.7097, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["### CE(Multi-class Cross Entropy)\n","- 다중 분류 문제에서 사용되는 손실함수"],"metadata":{"id":"nCaVXfXZNsSM"}},{"cell_type":"code","source":["# 4개 샘플, 2개 피처\n","x = torch.randn(4,2)\n","display(x)\n","x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"vT6HOeYVQq6m","executionInfo":{"status":"ok","timestamp":1732369534224,"user_tz":-540,"elapsed":451,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"4a0b5bc4-458c-471c-d66f-8edd4692b6ea"},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":["tensor([[-0.7658, -0.7506],\n","        [ 1.3525,  0.6863],\n","        [-0.3278,  0.7950],\n","        [ 0.2815,  0.0562]])"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 2])"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["x.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fpXCAMT6RPJu","executionInfo":{"status":"ok","timestamp":1732369535210,"user_tz":-540,"elapsed":562,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"bd68b636-e7cd-44d7-d451-78768f1a9c98"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.float32"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["x.shape[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"End4zqi6RLLi","executionInfo":{"status":"ok","timestamp":1732369535210,"user_tz":-540,"elapsed":2,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"2e159265-b5fc-4e90-ae83-9b9de59bf251"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["- 다중분류 문제만 정답데이터는 1차원 형태, 데이터타입은 int64 형태"],"metadata":{"id":"BDOIDMmiRXlp"}},{"cell_type":"code","source":["y = torch.tensor([0,1,2,1]) # 1차원 형태\n","display(y)\n","y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"S21AGm8ORaI_","executionInfo":{"status":"ok","timestamp":1732369584413,"user_tz":-540,"elapsed":593,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"c2860fcb-d742-4e3a-aca1-7d846346bf93"},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":["tensor([0, 1, 2, 1])"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["torch.Size([4])"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["y.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GLG0vtTxRaoZ","executionInfo":{"status":"ok","timestamp":1732369584413,"user_tz":-540,"elapsed":7,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"a35a0971-80ad-46a9-ee0a-fc33ca3d8039"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.int64"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["x.shape[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XNgq4w9CRzD4","executionInfo":{"status":"ok","timestamp":1732369663310,"user_tz":-540,"elapsed":445,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"b00e9af9-7be8-48ac-bbf2-312a341ba276"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["model = torch.nn.Linear(x.shape[1],3) # 입력 데이터 피처 개수: 2, 출력데이터 예측값 개수: 3\n","pred = model(x)\n","pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12dSpSxMRamY","executionInfo":{"status":"ok","timestamp":1732369667990,"user_tz":-540,"elapsed":432,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"4499ff89-1bb6-40d3-c851-a96f9ae846ad"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.2132, -0.3979, -0.7491],\n","        [-0.9222, -0.6024, -0.2185],\n","        [-0.0876, -0.1697,  0.0928],\n","        [-0.5427, -0.4781, -0.4303]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["loss_fn = torch.nn.CrossEntropyLoss()\n","loss_fn(pred, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ia0RM1pTRakF","executionInfo":{"status":"ok","timestamp":1732369690722,"user_tz":-540,"elapsed":448,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"a1e0bc82-9855-4f4f-bac7-46f96b555ff9"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.0237, grad_fn=<NllLossBackward0>)"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","source":["# 옵티마이터(Optimizer)\n","\n","- pytorch의 옵티마이저의 주요 파라미터\n","  - 첫 번째 인수 : 모델 파라미터\n","  - lr(learning rate) : 학습률\n","  - weight_decay : 가중치 감소를 적용하는데 사용되는 계수\n","(defalut = 0)\n","    - 가중치 감소 하지 않는 경우\n","L2정규화 지원"],"metadata":{"id":"T7q_CCk4R-Wq"}},{"cell_type":"code","source":["model.parameters()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ojhFWI5pRahi","executionInfo":{"status":"ok","timestamp":1732369999091,"user_tz":-540,"elapsed":622,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"4b0204ba-8316-41d9-ccce-90ec430b45ef"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<generator object Module.parameters at 0x7e72af914350>"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["optim = torch.optim.SGD(model.parameters(), lr = 0.001) # 경사하강법"],"metadata":{"id":"lZLG3cUwRafY","executionInfo":{"status":"ok","timestamp":1732370005994,"user_tz":-540,"elapsed":6394,"user":{"displayName":"이동규","userId":"01303882340467999707"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["# 가중치 업데이트\n","# 역전파 종류 후\n","\n","# loss.backward\n","optim.step()"],"metadata":{"id":"Rd-sowqORac_","executionInfo":{"status":"ok","timestamp":1732370005994,"user_tz":-540,"elapsed":11,"user":{"displayName":"이동규","userId":"01303882340467999707"}}},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":["## Adam"],"metadata":{"id":"2SbTNIU9TJTr"}},{"cell_type":"code","source":["optim = torch.optim.Adam(model.parameters())"],"metadata":{"id":"6M5fIRnFTFWQ","executionInfo":{"status":"ok","timestamp":1732370053556,"user_tz":-540,"elapsed":595,"user":{"displayName":"이동규","userId":"01303882340467999707"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["# 가중치 업데이트\n","# 역전파 종류 후\n","\n","# loss.backward\n","optim.step()"],"metadata":{"id":"JOvPPYAjTFTy","executionInfo":{"status":"ok","timestamp":1732370053556,"user_tz":-540,"elapsed":3,"user":{"displayName":"이동규","userId":"01303882340467999707"}}},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":["# 입력 데이터 텐서 변환\n","- 일반적으로 입력데이터 텐서의 dtype은 float32"],"metadata":{"id":"DNcG2yDyTRie"}},{"cell_type":"code","source":["x_train = torch.Tensor(train_ft) # Tensor > float32"],"metadata":{"id":"JH4KHr6MTFRh","executionInfo":{"status":"ok","timestamp":1732370194126,"user_tz":-540,"elapsed":454,"user":{"displayName":"이동규","userId":"01303882340467999707"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["x_train.shape, x_train.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ome7NxUwTFPb","executionInfo":{"status":"ok","timestamp":1732370194541,"user_tz":-540,"elapsed":10,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"4b3746fe-5589-4ef2-db15-cf7be653918c"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([916, 10]), torch.float32)"]},"metadata":{},"execution_count":64}]},{"cell_type":"markdown","source":["# 정답 데이터 텐서 변환"],"metadata":{"id":"BuhlZ4C2T6cp"}},{"cell_type":"code","source":["y_train = torch.Tensor(target.reshape(-1,1)) # reshape > 형태 변환"],"metadata":{"id":"wrSghg9KTFNJ","executionInfo":{"status":"ok","timestamp":1732370292153,"user_tz":-540,"elapsed":622,"user":{"displayName":"이동규","userId":"01303882340467999707"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["y_train.shape, y_train.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sT5RqNZUTFK2","executionInfo":{"status":"ok","timestamp":1732370292153,"user_tz":-540,"elapsed":6,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"30221fe7-2832-4471-f986-ea98e998c90f"},"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([916, 1]), torch.float32)"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"SdMp8XTpUJ8F","executionInfo":{"status":"ok","timestamp":1732370292153,"user_tz":-540,"elapsed":5,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"8ae892ed-8ce9-457a-c94a-f203cbb4edd2"},"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":67}]},{"cell_type":"markdown","source":["# 손실함수 객체 생성"],"metadata":{"id":"ai1yzSKrULbP"}},{"cell_type":"code","source":["loss_fn = torch.nn.BCEWithLogitsLoss() # 이진분류"],"metadata":{"id":"stDh2t09UJ4X","executionInfo":{"status":"ok","timestamp":1732370673417,"user_tz":-540,"elapsed":3,"user":{"displayName":"이동규","userId":"01303882340467999707"}}},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":["# 학습 loop구현\n","- 에폭 100회"],"metadata":{"id":"EFY9LAzQUXei"}},{"cell_type":"code","source":["torch.manual_seed(SEED) # 시드값 고정\n","model = torch.nn.Linear(x_train.shape[1],1).to(device) # 입력데이터 피처 개수: 10, 출력데이터 예측값 개수: 1, gpu에서 계산하기\n","optimizer = torch.optim.Adam(model.parameters()) # 최적화 > Adam\n","\n","model.train() # 학습모드 변경\n","for _ in range(100):\n","  pred = model(x_train.to(device)) # 예측\n","  loss = loss_fn(pred, y_train.to(device)) # 손실 계산 후 손실 텐서 반환\n","\n","  optimizer.zero_grad() # 기울기가 누적되므로, 역전파 실행 전 기울기 0으로 초기화\n","  loss.backward() # 역전파\n","  optimizer.step() # 가중치 업데이트\n","\n","  print(f'epoch loss : {loss.item()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XhmIAdxTUJ2E","executionInfo":{"status":"ok","timestamp":1732370676733,"user_tz":-540,"elapsed":534,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"352cbf8c-f01c-4f5b-c999-2e36ddba3628"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch loss : 0.6774646639823914\n","epoch loss : 0.6765610575675964\n","epoch loss : 0.6756608486175537\n","epoch loss : 0.6747638583183289\n","epoch loss : 0.673870325088501\n","epoch loss : 0.6729802489280701\n","epoch loss : 0.6720936298370361\n","epoch loss : 0.6712105870246887\n","epoch loss : 0.6703311800956726\n","epoch loss : 0.6694554686546326\n","epoch loss : 0.6685833930969238\n","epoch loss : 0.6677150130271912\n","epoch loss : 0.6668505072593689\n","epoch loss : 0.6659897565841675\n","epoch loss : 0.6651329398155212\n","epoch loss : 0.6642799973487854\n","epoch loss : 0.6634309887886047\n","epoch loss : 0.6625858545303345\n","epoch loss : 0.6617447733879089\n","epoch loss : 0.6609078049659729\n","epoch loss : 0.6600747108459473\n","epoch loss : 0.6592457890510559\n","epoch loss : 0.6584208607673645\n","epoch loss : 0.6576001048088074\n","epoch loss : 0.6567834615707397\n","epoch loss : 0.6559708714485168\n","epoch loss : 0.6551624536514282\n","epoch loss : 0.6543580889701843\n","epoch loss : 0.653558075428009\n","epoch loss : 0.6527620553970337\n","epoch loss : 0.6519702076911926\n","epoch loss : 0.6511824727058411\n","epoch loss : 0.6503990292549133\n","epoch loss : 0.6496195793151855\n","epoch loss : 0.648844301700592\n","epoch loss : 0.6480731964111328\n","epoch loss : 0.6473061442375183\n","epoch loss : 0.6465433239936829\n","epoch loss : 0.6457845568656921\n","epoch loss : 0.6450297832489014\n","epoch loss : 0.6442792415618896\n","epoch loss : 0.6435325741767883\n","epoch loss : 0.6427900791168213\n","epoch loss : 0.6420515775680542\n","epoch loss : 0.6413171291351318\n","epoch loss : 0.6405865550041199\n","epoch loss : 0.6398599743843079\n","epoch loss : 0.6391373872756958\n","epoch loss : 0.6384187340736389\n","epoch loss : 0.6377038359642029\n","epoch loss : 0.6369929313659668\n","epoch loss : 0.6362859010696411\n","epoch loss : 0.6355826258659363\n","epoch loss : 0.6348831653594971\n","epoch loss : 0.6341875195503235\n","epoch loss : 0.6334956884384155\n","epoch loss : 0.6328074932098389\n","epoch loss : 0.6321230530738831\n","epoch loss : 0.6314422488212585\n","epoch loss : 0.6307651996612549\n","epoch loss : 0.6300917863845825\n","epoch loss : 0.6294220089912415\n","epoch loss : 0.6287557482719421\n","epoch loss : 0.6280930638313293\n","epoch loss : 0.6274340748786926\n","epoch loss : 0.6267784237861633\n","epoch loss : 0.6261263489723206\n","epoch loss : 0.6254777908325195\n","epoch loss : 0.6248326897621155\n","epoch loss : 0.6241911053657532\n","epoch loss : 0.6235527992248535\n","epoch loss : 0.6229180097579956\n","epoch loss : 0.6222865581512451\n","epoch loss : 0.621658444404602\n","epoch loss : 0.6210337281227112\n","epoch loss : 0.6204123497009277\n","epoch loss : 0.6197942495346069\n","epoch loss : 0.619179368019104\n","epoch loss : 0.6185677647590637\n","epoch loss : 0.6179593801498413\n","epoch loss : 0.6173542737960815\n","epoch loss : 0.6167522668838501\n","epoch loss : 0.6161534786224365\n","epoch loss : 0.615557849407196\n","epoch loss : 0.6149653792381287\n","epoch loss : 0.6143760681152344\n","epoch loss : 0.6137897968292236\n","epoch loss : 0.6132066249847412\n","epoch loss : 0.6126264333724976\n","epoch loss : 0.6120493412017822\n","epoch loss : 0.6114752888679504\n","epoch loss : 0.6109041571617126\n","epoch loss : 0.6103360652923584\n","epoch loss : 0.6097709536552429\n","epoch loss : 0.6092087626457214\n","epoch loss : 0.6086494326591492\n","epoch loss : 0.6080930829048157\n","epoch loss : 0.6075395345687866\n","epoch loss : 0.6069889068603516\n","epoch loss : 0.6064411997795105\n"]}]},{"cell_type":"markdown","source":["# 테스트 데이터 구현"],"metadata":{"id":"pygbFNEIWBdD"}},{"cell_type":"code","source":["x_test = torch.Tensor(test_ft)\n","x_test.shape, x_test.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kOQf_UNCUJzj","executionInfo":{"status":"ok","timestamp":1732370886572,"user_tz":-540,"elapsed":453,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"8560fb26-f349-43b9-f672-21de90855caf"},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([393, 10]), torch.float32)"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["model.eval() # 평가모드\n","\n","sig = torch.nn.Sigmoid() # 확률값으로 변환\n","\n","with torch.no_grad(): # 예측과정에서 경사추적을 할 필요 없기 때문에 with문 안에서 예측 수행, @데코레이터로 활용 가능\n","  pred = model(x_test.to(device))\n","  pred = sig(pred) # 음수에서 양수 사이 예측확률 변환\n","  pred.to('cpu').numpy() # gpu에서 계산된 값을 cpu 이동 후 ndarray변환\n","pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u3mFppQLUJxW","executionInfo":{"status":"ok","timestamp":1732370887411,"user_tz":-540,"elapsed":2,"user":{"displayName":"이동규","userId":"01303882340467999707"}},"outputId":"7181a6c2-3b96-41b5-8d70-4baffb9c763c"},"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.4373],\n","        [0.4247],\n","        [0.3782],\n","        [0.6072],\n","        [0.6020],\n","        [0.5011],\n","        [0.4020],\n","        [0.4808],\n","        [0.4819],\n","        [0.6116],\n","        [0.3985],\n","        [0.6072],\n","        [0.5390],\n","        [0.5179],\n","        [0.5790],\n","        [0.3807],\n","        [0.4240],\n","        [0.5048],\n","        [0.4914],\n","        [0.3806],\n","        [0.3820],\n","        [0.5546],\n","        [0.6072],\n","        [0.3779],\n","        [0.3849],\n","        [0.5512],\n","        [0.3949],\n","        [0.4379],\n","        [0.4224],\n","        [0.5259],\n","        [0.4890],\n","        [0.4831],\n","        [0.3644],\n","        [0.5061],\n","        [0.4836],\n","        [0.5231],\n","        [0.6217],\n","        [0.4224],\n","        [0.3795],\n","        [0.3869],\n","        [0.5047],\n","        [0.5915],\n","        [0.3825],\n","        [0.3981],\n","        [0.4820],\n","        [0.3820],\n","        [0.4184],\n","        [0.5088],\n","        [0.3987],\n","        [0.5072],\n","        [0.5479],\n","        [0.3850],\n","        [0.4788],\n","        [0.5053],\n","        [0.4820],\n","        [0.5137],\n","        [0.4247],\n","        [0.4761],\n","        [0.6271],\n","        [0.3798],\n","        [0.3972],\n","        [0.3789],\n","        [0.4770],\n","        [0.6026],\n","        [0.3774],\n","        [0.5476],\n","        [0.4184],\n","        [0.4014],\n","        [0.5731],\n","        [0.3782],\n","        [0.4872],\n","        [0.5114],\n","        [0.3773],\n","        [0.6446],\n","        [0.4653],\n","        [0.5590],\n","        [0.4832],\n","        [0.5243],\n","        [0.4785],\n","        [0.3921],\n","        [0.5048],\n","        [0.4995],\n","        [0.3767],\n","        [0.6450],\n","        [0.5890],\n","        [0.5080],\n","        [0.5252],\n","        [0.4647],\n","        [0.5086],\n","        [0.3861],\n","        [0.6599],\n","        [0.3822],\n","        [0.3713],\n","        [0.3829],\n","        [0.3771],\n","        [0.4100],\n","        [0.6392],\n","        [0.4312],\n","        [0.4900],\n","        [0.3816],\n","        [0.4264],\n","        [0.4150],\n","        [0.3801],\n","        [0.6072],\n","        [0.4713],\n","        [0.3897],\n","        [0.6419],\n","        [0.4730],\n","        [0.4047],\n","        [0.5006],\n","        [0.3764],\n","        [0.3816],\n","        [0.5006],\n","        [0.4013],\n","        [0.3754],\n","        [0.3744],\n","        [0.5401],\n","        [0.5106],\n","        [0.5102],\n","        [0.4698],\n","        [0.4237],\n","        [0.3762],\n","        [0.3835],\n","        [0.5048],\n","        [0.3879],\n","        [0.3861],\n","        [0.6072],\n","        [0.3987],\n","        [0.6380],\n","        [0.5804],\n","        [0.3887],\n","        [0.5448],\n","        [0.3767],\n","        [0.5104],\n","        [0.3780],\n","        [0.4298],\n","        [0.3864],\n","        [0.3896],\n","        [0.3807],\n","        [0.4107],\n","        [0.4102],\n","        [0.6135],\n","        [0.6400],\n","        [0.6410],\n","        [0.4097],\n","        [0.4090],\n","        [0.3807],\n","        [0.4770],\n","        [0.3870],\n","        [0.5456],\n","        [0.5301],\n","        [0.3671],\n","        [0.5258],\n","        [0.3776],\n","        [0.3818],\n","        [0.6406],\n","        [0.4864],\n","        [0.3825],\n","        [0.5380],\n","        [0.4974],\n","        [0.4955],\n","        [0.4820],\n","        [0.4820],\n","        [0.3943],\n","        [0.3994],\n","        [0.6109],\n","        [0.4217],\n","        [0.6332],\n","        [0.3821],\n","        [0.3836],\n","        [0.3835],\n","        [0.4781],\n","        [0.5405],\n","        [0.4187],\n","        [0.5048],\n","        [0.4857],\n","        [0.4835],\n","        [0.5493],\n","        [0.3770],\n","        [0.5493],\n","        [0.5297],\n","        [0.6062],\n","        [0.3806],\n","        [0.5033],\n","        [0.3843],\n","        [0.4199],\n","        [0.3953],\n","        [0.3795],\n","        [0.3745],\n","        [0.5048],\n","        [0.4783],\n","        [0.3816],\n","        [0.3807],\n","        [0.5801],\n","        [0.4042],\n","        [0.5394],\n","        [0.3740],\n","        [0.4951],\n","        [0.6013],\n","        [0.4865],\n","        [0.5047],\n","        [0.3963],\n","        [0.4824],\n","        [0.4238],\n","        [0.4008],\n","        [0.4868],\n","        [0.4828],\n","        [0.4835],\n","        [0.3787],\n","        [0.3806],\n","        [0.6270],\n","        [0.3980],\n","        [0.5072],\n","        [0.5060],\n","        [0.6347],\n","        [0.3968],\n","        [0.6648],\n","        [0.5081],\n","        [0.4035],\n","        [0.3871],\n","        [0.4951],\n","        [0.4943],\n","        [0.3789],\n","        [0.3753],\n","        [0.4048],\n","        [0.3806],\n","        [0.5048],\n","        [0.4786],\n","        [0.4894],\n","        [0.3808],\n","        [0.5332],\n","        [0.3802],\n","        [0.4495],\n","        [0.4786],\n","        [0.5054],\n","        [0.5400],\n","        [0.4820],\n","        [0.5332],\n","        [0.4805],\n","        [0.5376],\n","        [0.3781],\n","        [0.3856],\n","        [0.5272],\n","        [0.5889],\n","        [0.4315],\n","        [0.3784],\n","        [0.4841],\n","        [0.3806],\n","        [0.3745],\n","        [0.4820],\n","        [0.3976],\n","        [0.5996],\n","        [0.3770],\n","        [0.4424],\n","        [0.3750],\n","        [0.5035],\n","        [0.6197],\n","        [0.4282],\n","        [0.4848],\n","        [0.3863],\n","        [0.4796],\n","        [0.3994],\n","        [0.3780],\n","        [0.4261],\n","        [0.5006],\n","        [0.4177],\n","        [0.3806],\n","        [0.5495],\n","        [0.6072],\n","        [0.5423],\n","        [0.5048],\n","        [0.6072],\n","        [0.3806],\n","        [0.4988],\n","        [0.6270],\n","        [0.3844],\n","        [0.6005],\n","        [0.3784],\n","        [0.3805],\n","        [0.4863],\n","        [0.3614],\n","        [0.3758],\n","        [0.3807],\n","        [0.3767],\n","        [0.3989],\n","        [0.5752],\n","        [0.3852],\n","        [0.4786],\n","        [0.4891],\n","        [0.3792],\n","        [0.4108],\n","        [0.3983],\n","        [0.4007],\n","        [0.4645],\n","        [0.6513],\n","        [0.4373],\n","        [0.4625],\n","        [0.4435],\n","        [0.6045],\n","        [0.5157],\n","        [0.4244],\n","        [0.5280],\n","        [0.4224],\n","        [0.4797],\n","        [0.4791],\n","        [0.5048],\n","        [0.6032],\n","        [0.4125],\n","        [0.5044],\n","        [0.3798],\n","        [0.5307],\n","        [0.3829],\n","        [0.4829],\n","        [0.3779],\n","        [0.5497],\n","        [0.4898],\n","        [0.3711],\n","        [0.5311],\n","        [0.4305],\n","        [0.4224],\n","        [0.3807],\n","        [0.6072],\n","        [0.5274],\n","        [0.3987],\n","        [0.3860],\n","        [0.5373],\n","        [0.5797],\n","        [0.3798],\n","        [0.4072],\n","        [0.4099],\n","        [0.3985],\n","        [0.4368],\n","        [0.4029],\n","        [0.3805],\n","        [0.5679],\n","        [0.4229],\n","        [0.5447],\n","        [0.6635],\n","        [0.4843],\n","        [0.4230],\n","        [0.4377],\n","        [0.6484],\n","        [0.3789],\n","        [0.4875],\n","        [0.5052],\n","        [0.3879],\n","        [0.5052],\n","        [0.4901],\n","        [0.3845],\n","        [0.4927],\n","        [0.6429],\n","        [0.5377],\n","        [0.5774],\n","        [0.5065],\n","        [0.3758],\n","        [0.6564],\n","        [0.3882],\n","        [0.3816],\n","        [0.5091],\n","        [0.3791],\n","        [0.5453],\n","        [0.4026],\n","        [0.3833],\n","        [0.4316],\n","        [0.4017],\n","        [0.4048],\n","        [0.6072],\n","        [0.4062],\n","        [0.4738],\n","        [0.4987],\n","        [0.3780],\n","        [0.5684],\n","        [0.3767],\n","        [0.4184],\n","        [0.3765],\n","        [0.6072],\n","        [0.4058],\n","        [0.4351],\n","        [0.4778],\n","        [0.3758],\n","        [0.6631],\n","        [0.5670],\n","        [0.4740],\n","        [0.3957],\n","        [0.4821],\n","        [0.5006],\n","        [0.3820],\n","        [0.4088],\n","        [0.3758],\n","        [0.5847],\n","        [0.3767],\n","        [0.3806],\n","        [0.3793]])"]},"metadata":{},"execution_count":72}]}]}